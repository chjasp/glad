{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d6561b-896d-448d-ad2d-777adbb7d21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bffc1181-d6e2-43fd-b8be-ec34846b9b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019c57b5-e16a-4d58-878f-50c2c94d8932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"hl_podcast_wmemory_stage_2.txt\", \"r\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c3669a-b5d1-454c-8213-a01937050dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "\n",
    "documents = text_splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960e5450-1a29-4d56-aaba-c334ca925963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_gpt_query(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef99f0b1-da0d-4c50-a148-9570d09d96e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_split(result):\n",
    "    if result is None or result == \"\":\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        result_array = result.replace(\"\\n\", \"\").split(\"- \")\n",
    "        if len(result_array) > 1:\n",
    "            return result_array[1:]\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99aa0ba-87d3-4087-8305-705b5a3f9229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Prompts:\n",
    "    @staticmethod\n",
    "    def advice_prompt(content):\n",
    "        prompt = f\"\"\"----- INSTRUCTION -----\n",
    "In the following, I will provide you a part of a \\\n",
    "podcast-transcript. This podcast covers health-related topics. \\\n",
    "I need you to extract actionable advice from each transcript. \\\n",
    "Each advice should be formulated as an instruction. \\\n",
    "Advices should be enumerated with an '-'. \\\n",
    "If there is no actionable advice in the transcript, you should return 'No Advice'.\n",
    "----- TRANSCRIPT ----\n",
    "{content}\n",
    "----- ADVICE -----\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    @staticmethod \n",
    "    def summary_prompt(content):\n",
    "        prompt = f\"\"\"----- INSTRUCTION -----\n",
    "Summarize the following text in one word, or two words at max. \n",
    "----- TEXT ----\n",
    "Here's the transcript: {content}\n",
    "----- SUMMARY -----\"\"\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f40e5a-5f9d-45f1-9547-954b704cf616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:54<00:00,  5.21s/it]\n"
     ]
    }
   ],
   "source": [
    "instructions = []\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    content = doc.page_content\n",
    "    prompt = Prompts.advice_prompt(content)\n",
    "    \n",
    "    result = chat_gpt_query(prompt)\n",
    "    result_array = safe_split(result)\n",
    "    instructions.extend(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b979150e-8ce7-4e0d-b8f1-7bdcfe25bdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [01:18<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_data = []\n",
    "video_id = \"CQlTmOFM4Qs\"\n",
    "\n",
    "for ins in tqdm(instructions):\n",
    "    prompt = Prompts.summary_prompt(ins)\n",
    "    summary = chat_gpt_query(prompt)\n",
    "    raw_data.append((summary, ins, video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c778787-fdfe-4e1c-b289-5efa8b9c177d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_to_insert = [{\"index\": index, \"advice\": advice, \"video_id\": video_id} for index, advice, video_id in raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cecec7d9-5a0d-42e7-89b2-d10ef91343d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 'Working memory',\n",
       "  'advice': 'Understand what working memory is and how it is related to attention.',\n",
       "  'video_id': 'CQlTmOFM4Qs'},\n",
       " {'index': 'Memory improvement',\n",
       "  'advice': 'Learn about tools and strategies to improve working memory.',\n",
       "  'video_id': 'CQlTmOFM4Qs'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_insert[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6053a13-9377-4e2a-be6e-64da34299f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "table_id = \"steam-378309.huberman.advice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c29a8b-4c4f-42ca-a2db-e5c9cc1d8a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows have been added.\n"
     ]
    }
   ],
   "source": [
    "errors = client.insert_rows_json(table_id, rows_to_insert)\n",
    "\n",
    "if errors == []:\n",
    "    print(\"New rows have been added.\")\n",
    "else:\n",
    "    print(\"Encountered errors while inserting rows: {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "193bf733-7ab5-4b49-9001-8304a0b32462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E7W4OQfJWdw 147\n",
      "CQlTmOFM4Qs 152\n"
     ]
    }
   ],
   "source": [
    "job = client.query(\"select video_id, count(*) from `steam-378309.huberman.advice` group by video_id\")\n",
    "\n",
    "for result in job.result():\n",
    "    print(*result)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
