{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "357d447a-bcdf-4205-b6f6-be27d9421da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53902325-bf37-4872-ae74-1bd4b3f823c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GCP_API_KEY\")\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "channel_name = \"@hubermanlab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f4e563-5e33-4741-881e-435b75cb041b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YouTubeHelper:\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    def get_channel_id(self, channel_name):\n",
    "        request = self.youtube.search().list(\n",
    "            q=channel_name,\n",
    "            type='channel',\n",
    "            part='id',\n",
    "            maxResults=1\n",
    "        )\n",
    "        response = request.execute()\n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_video_ids(self, channel_id):\n",
    "        channel_response = self.youtube.channels().list(\n",
    "            id=channel_id,\n",
    "            part='contentDetails'\n",
    "        ).execute()\n",
    "        upload_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        videos = []\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            playlist_response = self.youtube.playlistItems().list(\n",
    "                playlistId=upload_playlist_id,\n",
    "                part='contentDetails',\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "            videos += [item['contentDetails']['videoId'] for item in playlist_response['items']]\n",
    "            next_page_token = playlist_response.get('nextPageToken')\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "        return videos\n",
    "\n",
    "    def get_transcript(self, video_id):\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            output = ''\n",
    "            for x in transcript:\n",
    "                sentence = x['text']\n",
    "                output += f'{sentence}'\n",
    "            return output, transcript\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b993487-c7b9-4e98-93ce-db08e4985a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    \n",
    "    @staticmethod\n",
    "    def query_chatgpt(client, prompt):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_text(chunk_size, text):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = chunk_size,\n",
    "            chunk_overlap = 0\n",
    "        )\n",
    "        documents = text_splitter.create_documents([text])\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73595bd3-cd5d-412d-b286-8f0be4e8b80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Prompts:\n",
    "    @staticmethod\n",
    "    def transcript_fix(content):\n",
    "        prompt = f\"\"\"----- INSTRUCTION -----\n",
    "In the following, I will provide you a part of a \\\n",
    "podcast-transcript. This podcast covers health-related topics. \\\n",
    "However, the transcript is badly formatted. The following issues can occur: \\\n",
    "(1) Punctuation is missing completely (2) whitespace between words is missing. \\\n",
    "(3) large and lower case is oftentimes off. \\\n",
    "In the following I will give you chunks of this transcript that you have to correct. \\\n",
    "It's possible that the sentence continues after the transcript-snippet ends, \\\n",
    "insert a ' ... ' instead of punctuation. Here's the transcript:\n",
    "----- TRANSCRIPT ----\n",
    "{content}\n",
    "----- CORRECTED TRANSCRIPT ----\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    @staticmethod\n",
    "    def fix_faulty_splits(content):\n",
    "        prompt = f\"\"\"----- INSTRUCTION -----\n",
    "In the following, I will provide you a part of a \\\n",
    "podcast-transcript. This podcast covers health-related topics. \\\n",
    "However, the transcript is badly formatted. The following issue can occur: \\\n",
    "When a part of the transcript ends with '...' \\\n",
    "you have to check whether the punctuation makes sense here. If not, delete it along \\\n",
    "with the '...'-indicator. Here's the transcript:\n",
    "----- TRANSCRIPT ----\n",
    "{content}\n",
    "----- CORRECTED TRANSCRIPT ----\"\"\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9007970d-b6b0-4c40-b4c8-87c88909c1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yt_helper = YouTubeHelper(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5af46452-2709-4ead-8d7b-17428bad6530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_id = yt_helper.get_channel_id(channel_name)\n",
    "video_ids = yt_helper.get_video_ids(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95a100b7-9da1-4832-8b7a-7419f2c2fa15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output, transcript = yt_helper.get_transcript(\"CQlTmOFM4Qs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02e832e9-f551-454a-b6dc-78f54eb06ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents_stage_1 = TextProcessor.split_text(400, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276f1ae-365e-43d9-84c9-c728b558a32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [15:26<00:00,  3.86s/it]\n"
     ]
    }
   ],
   "source": [
    "stage_1_text = \"\"\n",
    "\n",
    "for doc in tqdm(documents_stage_1):\n",
    "    original = doc.page_content\n",
    "    prompt = Prompts.transcript_fix(original)\n",
    "    processed = TextProcessor.query_chatgpt(client, prompt)\n",
    "    \n",
    "    stage_1_text += processed + \"..\" if processed[-1] == \".\" and processed[-2] != \".\" else processed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820b0e9-568e-48e7-af39-94c46de315a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"hl_podcast_wmemory_stage_1.txt\", \"w\") as f:\n",
    "    f.write(stage_1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e2210c42-510c-477b-a41b-2165683c0688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents_stage_2 = TextProcessor.split_text(750, stage_1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5a2f8cf3-95a6-43b0-b28e-2ad534a27fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [14:51<00:00,  6.42s/it]\n"
     ]
    }
   ],
   "source": [
    "stage_2_text = \"\"\n",
    "\n",
    "for doc in tqdm(documents_stage_2):\n",
    "    original = doc.page_content\n",
    "    prompt = Prompts.fix_faulty_splits(original)\n",
    "    processed = TextProcessor.query_chatgpt(client, prompt)\n",
    "    processed = processed.replace(\"\\n\", \"\")\n",
    "    \n",
    "    stage_2_text += processed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "858b4234-91c9-4e02-b588-cf2df0c960e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Huberman Lab Podcast, where we discuss science and science-based tools for everyday life. [Music] I'm Andrew Huberman, and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. Today, we are discussing working memory. Working memory is a special category of memory in which we are able to hold small amounts of information in our mind for short periods of time. It is also very closely related to attention. So for any of you that are interested in how to develop better focus and attention, understanding what working memory is and some of the things that you can do to improve your working memory can be very beneficial. Today, I'm going to talk about what working memory is, including some of the things that you can do to improve it.Underlying biology, although I promise irrespective of whether or not you know any biology or are you an expert in biology, I'll make the conversation accessible to you. In addition, I will talk about tools to improve working memory and I'll also compare working memory to other forms of memory like long-term memory and short-term memory. And through that understanding, I'm confident that you'll be able to develop better focus as well as be able to commit certain forms of information to your short and long-term memory stores. Before we begin, I'd like to emphasize that this podcast is separate for my teaching and research roles at Stanford. It is, however, part of my desire and effort to bring zero cost to consumer information about.Science and science-related tools to the general public. In keeping with that theme, I'd like to thank the sponsors of today's podcast. Our first sponsor is MatinaMatina.Makes loose leaf and ready to drink Yerba Mate. I often discuss Yerba Mate's benefits, such as regulating blood sugar, its high antioxidant content, the ways that it can improve digestion, and possible neuroprotective effects. I also drink Yerba Mate because I love the taste.While there are a lot of different choices of Yerba Mate drinks out there, I love Matina because, again, they have the no sugar variety as well as the fact that both their loose leaf and their canned varieties are of the absolute best quality. So much so that I decided to become a partial owner in the company. Although I must say even if they hadn't allowed me to do that, I would be drinking Matina. It is the cleanest tasting and best yerba mate you can find. I love the taste of brewed loose leaf Matina yerba mate and I particularly love the taste of Maa's new canned cold brew, zero sugar, yerba mate, which I personally helped them develop. If you'd like to try Matina, go to drinkmaa.com/huberman right now. Matina is offering a free trial.1lb bag of loose leaf yerba mate tea and free shipping with the purchase of two cases of their cold brew yerba mate. Again, that's drinkmaa.com/huberman to get the free bag of yerba mate loose leaf tea and free shipping. Today's episode is also brought to us by BetterHelp. BetterHelp offers professional therapy with a licensed therapist carried out online. Now, I've been going to therapy for well over 30 years. Initially, I didn't have a choice. It was a condition of being allowed to stay in school. But pretty soon, I realized that therapy is extremely valuable. In fact, I consider doing regular therapy just as important as getting regular exercise, including cardiovascular exercise and resistance training, which of course I also do.Every week. The reason I know therapy is so valuable is that if you can find a therapist with whom you can develop a really good rapport, you not only get terrific support for some of the challenges in your life, but you also can derive tremendous insights from that therapy. Insights that can allow you to better not just your emotional life and your relationship life, but of course also the relationship to yourself and to your professional life, to all sorts of career goals. In fact, I see therapy as one of the key components for meshing together all aspects of one's life and being able to really direct one's focus and attention toward what really matters. If you'd like to try BetterHelp, go to betterhelp.com, huberman, to get 10% off.Your first month. Again, that's betterhelp.com/huberman. Today's episode is also brought to us by Helix sleep. Helix IC sleep makes mattresses and pillows that are of the absolute highest quality. I've spoken many times before on this and other podcasts about the fact that sleep is the foundation of mental health, physical health, and performance. One of the key things to getting a great night's sleep is to make sure that your mattress matches your sleep requirements. The Helix website has a brief two-minute quiz that, if you go to it, will ask you questions such as: do you sleep on your back, your side, or your stomach? Do you tend to run hot or cold during the middle of the night? As well as some other questions that allow you to...Determine the optimal mattress for you. When I took the quiz, I personally matched to their dusk mattress. D, which has allowed me to significantly improve my sleep. So if you're interested in significantly improving your sleep, go to helixsleep.com/huberman, take their brief two-minute quiz, and they'll match you to a customized mattress. And you'll get up to $350 off any mattress order and two free pillows. So, again, if you're interested in trying Helix, go to helixsleep.com/huberman for up to $350 off and two free pillows. Okay, let's talk about working memory and let's start off this discussion by comparing working memory to other forms of memory that most people are more familiar with or at least when most people hear the wordMemory, they typically are thinking about long-term memory like one's ability to remember the capitals of states or countries, different continents, directions from one location to another, even one's name - all of those things are examples of long-term memory. Now, I want to emphasize that long-term memory \n"
     ]
    }
   ],
   "source": [
    "print(stage_2_text[:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b6f59d2-cff5-4642-ae62-f779fd01f274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"hl_podcast_wmemory_stage_2.txt\", \"w\") as f:\n",
    "    f.write(stage_2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4632ac7-f555-4953-b0e4-74119628db4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://hl_podcast_wmemory_stage_2.txt [Content-Type=text/plain]...\n",
      "/ [1 files][ 96.8 KiB/ 96.8 KiB]                                                \n",
      "Operation completed over 1 objects/96.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp hl_podcast_wmemory_stage_2.txt gs://legalm-staging/huberman_lab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93077116-6a6d-4bfd-97ea-e94f8a096850",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://hl_podcast_wmemory_stage_1.txt [Content-Type=text/plain]...\n",
      "/ [1 files][ 97.7 KiB/ 97.7 KiB]                                                \n",
      "Operation completed over 1 objects/97.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp hl_podcast_wmemory_stage_1.txt gs://legalm-staging/huberman_lab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c532c-fefd-429c-b789-153fd7544093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
